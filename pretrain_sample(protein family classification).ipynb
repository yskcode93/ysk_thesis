{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b70230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "devices = \"0,1,2,3,4,5,6,7\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = devices\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12361'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24341c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from thesis_code.pretrain import train, train_, train_fam_cls\n",
    "from thesis_code.model import TransformerEncoder, SPgMLP\n",
    "from sample.gMLP.model import MultigMLP, gMLP\n",
    "import torch.nn as nn\n",
    "# for transformer\n",
    "config_transformer = {\n",
    "    \"n_tokens\": 66,\n",
    "    \"seq_len\": 700,\n",
    "    \"n_layers\": 12,\n",
    "    \"n_heads\": 2,\n",
    "    \"query_dimensions\": 128,\n",
    "    \"value_dimensions\": 128,\n",
    "    \"feed_forward_dimensions\": 256,\n",
    "    \"attention_type\": \"linear\",\n",
    "    \"n_species\": 34\n",
    "}\n",
    "# for gMLP\n",
    "config_gmlp = {\n",
    "    \"num_tokens\": 66,\n",
    "    \"dim\": 256,\n",
    "    \"depth\": 32,\n",
    "    \"seq_len\": 701,\n",
    "    \"heads\": 1,\n",
    "    \"ff_mult\": 2,\n",
    "    \"attn_dim\": None,\n",
    "    \"prob_survival\": 1.,\n",
    "    \"causal\": False,\n",
    "    \"circulant_matrix\": True,\n",
    "    \"shift_tokens\": 0,\n",
    "    \"act\": nn.Tanh(),\n",
    "    \"n_species\": 278\n",
    "}\n",
    "# for gmlp\n",
    "config_gmlp = {\n",
    "    \"n_tokens\": 67,\n",
    "    \"d_in\": 512,\n",
    "    \"d_ffn\": 1024,\n",
    "    \"max_len\": 701,\n",
    "    \"n_layers\": 32,\n",
    "    \"act\": nn.Tanh(),\n",
    "    \"n_species\": 278,\n",
    "}\n",
    "n_epochs = 1500\n",
    "batch_size = 64\n",
    "lr = 2e-4\n",
    "warmup = 0.1\n",
    "use_apex = True\n",
    "strain_ids = [\n",
    "    22096, 15376, 22118, 22146, 8415, 21918, 20123, 452, 18655, 6750, 17659, 421, 22191, 21978, 12722, 17400,\\\n",
    "    15093, 20120, 20313, 20114, 22204, 19272, 17982, 19601, 21259, 22091, 1375, 10427, 18739, 18441, 22200, 22201, 22202, 22203\n",
    "]\n",
    "strain_ids = [\n",
    "    22096, 15376, 22118, 22146, 8415\n",
    "]\n",
    "log_interval = 10\n",
    "save_interval = 500\n",
    "log = \"./Result/pretrain/protein_family.log\"\n",
    "checkpoint_path = \"./Result/pretrain/protein_family.pt\"\n",
    "pretrain_class = MultigMLP\n",
    "config = config_gmlp\n",
    "\n",
    "nprocs = len(devices.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca69c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.spawn(train_fam_cls, nprocs=nprocs, args=(nprocs, pretrain_class, config, n_epochs, batch_size, lr, warmup, use_apex,\\\n",
    "    log_interval, save_interval, False, log, checkpoint_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
